{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MultiHead Attention Unit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-03-10T04:16:09.398413Z",
     "end_time": "2024-03-10T04:16:15.724777Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    d_k = q.shape[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled = scaled + mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    output = torch.matmul(attention, v)\n",
    "    return output, attention"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-10T04:17:24.900876Z",
     "end_time": "2024-03-10T04:17:24.920620Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_model // n_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim, 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, sequence_length, input_dim = x.size()\n",
    "        print(f'x.size(): {x.size()}')\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f'qkv.size(): {qkv.size()}')\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.n_heads, 3 * self.head_dim)\n",
    "        print(f'qkv.size(): {qkv.size()}')\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        print(f'qkv.size(): {qkv.size()}')\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        print(f'q: {q.size()}\\nk: {k.size()}\\nv: {v.size()}\\n')\n",
    "        values, attention = scaled_dot_product_attention(q, k, v, mask=mask)\n",
    "        print(f'values.size(): {values.size()}\\nattention.size(): {attention.size()}')\n",
    "        values = values.reshape(batch_size, sequence_length, self.n_heads * self.head_dim)\n",
    "        print(f'values.size(): {values.size()}')\n",
    "        out = self.linear_layer(values)\n",
    "        print(f'out: {out.size()}')\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-10T04:17:25.654199Z",
     "end_time": "2024-03-10T04:17:25.672402Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([30, 5, 1024])\n",
      "qkv.size(): torch.Size([30, 5, 1536])\n",
      "qkv.size(): torch.Size([30, 5, 8, 192])\n",
      "qkv.size(): torch.Size([30, 8, 5, 192])\n",
      "q: torch.Size([30, 8, 5, 64])\n",
      "k: torch.Size([30, 8, 5, 64])\n",
      "v: torch.Size([30, 8, 5, 64])\n",
      "\n",
      "values.size(): torch.Size([30, 8, 5, 64])\n",
      "attention.size(): torch.Size([30, 8, 5, 5])\n",
      "values.size(): torch.Size([30, 5, 512])\n",
      "out: torch.Size([30, 5, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[-0.1623, -0.1653,  0.1396,  ...,  0.3152,  0.0166,  0.0153],\n         [ 0.0114,  0.2720, -0.0178,  ...,  0.2065,  0.0054,  0.0868],\n         [ 0.1590,  0.1196,  0.0500,  ..., -0.0605, -0.2720, -0.1128],\n         [ 0.4091,  0.1578, -0.1297,  ...,  0.1036, -0.0105, -0.0956],\n         [-0.1116,  0.0521,  0.1413,  ..., -0.1493,  0.0577,  0.3494]],\n\n        [[-0.1405,  0.1221,  0.0095,  ...,  0.0075, -0.2480,  0.0052],\n         [-0.1524,  0.3020, -0.1569,  ...,  0.0943, -0.0375, -0.0781],\n         [ 0.0838,  0.0777, -0.0320,  ...,  0.1853,  0.1358,  0.1878],\n         [-0.0298, -0.0100,  0.0615,  ..., -0.0851, -0.1713, -0.1433],\n         [ 0.0863,  0.0296,  0.1967,  ..., -0.1727,  0.1416,  0.1266]],\n\n        [[-0.0207,  0.1130, -0.1000,  ..., -0.1030, -0.0508,  0.0267],\n         [-0.1799, -0.0367, -0.0710,  ...,  0.1104, -0.0764, -0.0496],\n         [-0.0626, -0.0912, -0.0757,  ...,  0.1202, -0.1761, -0.2932],\n         [-0.0082, -0.2578,  0.2435,  ..., -0.1285,  0.0730, -0.2077],\n         [-0.1941, -0.2180,  0.1892,  ..., -0.1640, -0.1988,  0.0351]],\n\n        ...,\n\n        [[-0.2723, -0.1517,  0.0153,  ...,  0.2773,  0.1055,  0.0608],\n         [ 0.2414,  0.1842, -0.3053,  ...,  0.1190, -0.0153,  0.0916],\n         [-0.0952, -0.1610, -0.0511,  ...,  0.2378, -0.3794, -0.0974],\n         [-0.1962, -0.1748,  0.1260,  ..., -0.0636, -0.2879,  0.4250],\n         [-0.0017,  0.2187, -0.0231,  ..., -0.0462,  0.1388,  0.1223]],\n\n        [[ 0.0985,  0.0768,  0.0430,  ...,  0.0728,  0.0054,  0.0449],\n         [ 0.1634,  0.1014, -0.0598,  ...,  0.0921,  0.3684,  0.0134],\n         [ 0.1475, -0.0348,  0.0387,  ..., -0.2029, -0.1087,  0.0254],\n         [-0.1521, -0.0599, -0.1105,  ..., -0.1225,  0.0686, -0.3332],\n         [ 0.1885,  0.1478,  0.3510,  ..., -0.0390,  0.0848,  0.2815]],\n\n        [[-0.1748, -0.0941,  0.0906,  ...,  0.1280, -0.0842, -0.0265],\n         [ 0.1847,  0.0287, -0.2073,  ...,  0.1483, -0.1724, -0.3798],\n         [-0.1252,  0.0867,  0.1650,  ..., -0.1808,  0.0930,  0.0426],\n         [-0.1147,  0.0959, -0.2381,  ..., -0.0675, -0.2078, -0.2517],\n         [ 0.1353, -0.0182, -0.0751,  ..., -0.2093, -0.1267, -0.1559]]],\n       grad_fn=<ViewBackward0>)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 30\n",
    "\n",
    "input_dim = 1024\n",
    "n_heads = 8\n",
    "d_model = 512\n",
    "\n",
    "sequence_length = 5\n",
    "x = torch.randn((batch_size, sequence_length, input_dim))\n",
    "\n",
    "model = MultiHeadAttention(input_dim, d_model, n_heads)\n",
    "out = model.forward(x)\n",
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-10T04:17:26.504159Z",
     "end_time": "2024-03-10T04:17:26.554404Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
